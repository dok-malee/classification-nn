{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "TfidfVectorizer Parameters:\n",
    "1. **sublinear_tf (default=False):**\n",
    "   - It applies sublinear scaling to the term frequency. Sublinear scaling replaces tf with 1 + log(tf).\n",
    "\n",
    "2. **max_df (default=1.0):**\n",
    "   - When building the vocabulary, it ignores terms that have a document frequency strictly higher than the given threshold (expressed as an absolute count or a proportion of the documents if float). This can be used to remove terms that are too frequent and likely to be irrelevant.\n",
    "\n",
    "3. **min_df (default=1):**\n",
    "   - When building the vocabulary, it ignores terms that have a document frequency strictly lower than the given threshold. This could be an integer count or a proportion of documents as a float.\n",
    "\n",
    "4. **stop_words (default=None):**\n",
    "   - If \"english\", a built-in stop word list for English is used. You can also pass your own list of stop words, or None to indicate no stop words. Stop words are common words (e.g., \"the\", \"and\", \"is\") that are often removed because they don't contribute much to the content of the document.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf60c9dacf4fb05f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Batch:**\n",
    "- A batch is a subset of the training dataset used in one iteration of the training process.\n",
    "- Instead of updating the model's parameters based on the entire training dataset at once (which can be computationally expensive), training is often performed in smaller batches.\n",
    "- The size of the batch is a hyperparameter known as the batch size.\n",
    "- Common batch sizes include 32, 64, 128, and so on. Larger batch sizes can lead to faster training, but smaller batch sizes may offer more noise in the parameter updates.\n",
    "\n",
    "**Epoch:**\n",
    "- An epoch is one complete pass through the entire training dataset during the training process.\n",
    "- During each epoch, the model sees and processes every example in the training dataset once.\n",
    "- The number of epochs is a hyperparameter that defines how many times the learning algorithm will work through the entire training dataset.\n",
    "- Training for more epochs allows the model to see the data multiple times, potentially improving its performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e0159c7a41a4545"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

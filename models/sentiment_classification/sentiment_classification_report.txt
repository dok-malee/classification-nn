Sentiment Classfication FFNN Model with Tfidf Unigram Vectors:

Hyperparameters:
hidden_sizes = [128, 64]
batch_size = 32
learning_rate = 0.05
num_epochs = 20 * 5 = 100

Train:
              precision    recall  f1-score   support

    negative       1.00      1.00      1.00     20015
    positive       1.00      1.00      1.00     19985

    accuracy                           1.00     40000
   macro avg       1.00      1.00      1.00     40000
weighted avg       1.00      1.00      1.00     40000

Eval:
              precision    recall  f1-score   support

    negative       0.88      0.87      0.87      4985
    positive       0.87      0.88      0.88      5015

    accuracy                           0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.87      0.87      0.87     10000



Sentiment Classfication FFNN Model with Tfidf Bigram Vectors:

Hyperparameters:
hidden_sizes = [128, 64]
batch_size = 32
learning_rate = 0.05
num_epochs = 20 * 5 = 100

Train:
              precision    recall  f1-score   support

    negative       1.00      1.00      1.00     20015
    positive       1.00      1.00      1.00     19985

    accuracy                           1.00     40000
   macro avg       1.00      1.00      1.00     40000
weighted avg       1.00      1.00      1.00     40000

Eval:
              precision    recall  f1-score   support

    negative       0.88      0.87      0.87      4985
    positive       0.87      0.88      0.88      5015

    accuracy                           0.87     10000
   macro avg       0.88      0.87      0.87     10000
weighted avg       0.87      0.87      0.87     10000



Sentiment Classfication FFNN Model with Word2Vec Embeddings:

Hyperparameters:
hidden_sizes = [128, 64]
batch_size = 32
learning_rate = 0.05
num_epochs = 500 * 5 = 2500

Train:
              precision    recall  f1-score   support

    negative       0.67      0.72      0.69     20015
    positive       0.69      0.65      0.67     19985

    accuracy                           0.68     40000
   macro avg       0.68      0.68      0.68     40000
weighted avg       0.68      0.68      0.68     40000
Eval:
              precision    recall  f1-score   support

    negative       0.58      0.64      0.61      4985
    positive       0.60      0.55      0.57      5015

    accuracy                           0.59     10000
   macro avg       0.59      0.59      0.59     10000
weighted avg       0.59      0.59      0.59     10000



Sentiment Classfication FFNN Model with GloVe Embeddings:

Hyperparameters:
hidden_sizes = [128, 64]
batch_size = 32
learning_rate = 0.05
num_epochs = 500 * 5 = 2500

Train:

              precision    recall  f1-score   support

    negative       0.94      0.94      0.94     20015
    positive       0.94      0.94      0.94     19985

    accuracy                           0.94     40000
   macro avg       0.94      0.94      0.94     40000
weighted avg       0.94      0.94      0.94     40000

Eval:
              precision    recall  f1-score   support

    negative       0.78      0.77      0.78      4985
    positive       0.78      0.78      0.78      5015

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000



